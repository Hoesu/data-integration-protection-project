# 데이터 통합과 정보보호 팀 프로젝트 현황 및 마무리 계획

**팀원**: 이동진, 이승후, 이세원, 정회수

---

# 0. 현재 진행상황
```bash
.
├── builder.py
├── database
│   ├── ✅ actions.py
│   ├── ✅ __init__.py
│   └── tables
│       ├── ✅ base.py
│       ├── card_credit_info.py
│       ├── ✅ card_user_info.py
│       ├── individual_cb.py
│       └── ✅ __init__.py
│
├── __init__.py
├── metric
│   ├── categorical.py
│   ├── combined.py
│   ├── numerical.py
│   └── __init__.py
│
├── preprocess
│   ├── allocation.py
│   ├── imputation.py
│   ├── normalization.py
│   └── __init__.py
│
├── risk
│   ├── attribute.py
│   ├── combined.py
│   ├── identity.py
│   └── __init__.py
│
└── utils
    ├── config.py
    ├── logger.py
    └── __init__.py
```

## 1. 프로젝트 목표

다양한 데이터 합성, 마스킹 기법을 거친 공공 금융 데이터셋에 대한 개별 관측치와 데이터셋 단위 노출 위험 수준을 제시한다. 또한, 다양한 상황을 고려하여 최소한 3개 데이터셋에 제안 방법론을 적용한다.

## 2. 문제 정의

공공 금융 데이터는 개인정보 보호를 위해 속성명이 비식별화되고 값이 변형된 상태로 제공된다. 그러나 데이터 내부의 관측치 간 관계 구조는 여전히 보존되어 있어, 일부 관측치는 서로 밀접하게 연결되거나 고립되는 등 구조적 패턴이 남아 있다. 이러한 관계적 특성은 잠재적 재식별 위험을 시사한다.

따라서 속성의 의미 해석에 의존하지 않고, 데이터의 관계 구조만으로 노출 위험을 정량화하는 그래프 기반 접근법을 제안한다. 각 관측치를 노드로, 거리 기반 관계를 엣지로 정의하여 네트워크를 구성하고, 연결 강도나 중심성 등 그래프 지표를 활용해 데이터셋의 노출 위험도를 평가한다. 이로써 데이터의 구조적 특성을 반영하면서도 의미 정보에 의존하지 않는 위험 측정 체계를 제시한다.

## 3. 활용 데이터

AIhub에서 제공하는 금융 합성 데이터를 사용한다. 금융기관으로부터 획득한 데이터의 특성을 인공지능 알고리즘으로 학습해 생성한 합성 데이터셋이다. 신용 카드의 회원, 신용, 승인매출, 청구, 잔액, 채널, 마케팅, 성과에 대한 정보와 개인, 기업, 통신카드의 CB 정보를 제공한다.

## 4. 환경 구축

약 30GB에 달하는 대용량 데이터셋을 효율적으로 관리하고, 실험 과정을 편리하게 자동화하기 위해 AWS EC2 인스턴스 위에 Postgres DB를 띄워 팀원들이 공용으로 사용한다. 또한, SQLAlchemy를 활용하여 Python 스크립트에서 직접 DB와 상호작용하는 커넥터를 구축하고, 모든 코드는 UV를 활용하여 구축한 가상환경에서 실행될 수 있도록 한다.

## 5. 데이터 전처리 및 메트릭 설정

그래프 네트워크 구축을 위해 모든 데이터 속성을 거리 메트릭 적용이 가능한 형태로 변환한다. 속성은 처리 방식에 따라 수치형과 범주형으로 구분한다.

두 관측치 간의 최종 거리는 각 속성 그룹별 평균 거리를 가중 결합하여 산출한다. 수치형 그룹에는 L2, L1, Mahalanobis 등 수치형 거리 메트릭을, 범주형 그룹에는 Levenshtein, Jaccard 거리 등 문자열 기반 거리 메트릭을 적용한다.

속성의 의미적 해석에 의존하지 않고 구조적 패턴만을 활용하므로, 임베딩 벡터를 통한 유사도 측정보다는 문자열 비교 기반 거리 측정을 사용한다. 이를 통해 각 케이스 간 균등한 거리 차이를 보장하고, 비식별화된 데이터에서도 일관된 거리 계산이 가능하다.

결측치가 존재하는 경우, 해당 속성을 제외한 나머지 속성들로 계산한 거리 기반으로 가장 유사한 K개의 관측치를 식별한다. 이들의 평균값(수치형) 또는 최빈값(범주형)으로 대체한다. 이를 통해 결측치로 인한 정보 손실을 최소화하면서 그래프 네트워크 구축에 필요한 완전한 데이터를 확보한다.

## 6. 그래프 네트워크 구축 방안

전처리된 데이터의 각 관측치를 노드로 정의하고, 지정한 거리 메트릭을 기반으로 K-Nearest Neighbors(KNN) 그래프를 구축한다. O(n²) 시간 복잡도의 KNN 계산을 대용량 데이터에 그대로 적용시키면 부담이 크니, Faiss GPU 가속 라이브러리를 활용하여 KNN 검색을 수행한다.

각 노드에 대해 거리 기준 상위 K개의 가장 유사한 노드와 엣지를 생성하여 희소 그래프를 구성한다. 엣지에는 거리 기반 가중치를 부여하여 연결 강도를 표현한다. 가중치는 거리의 역변환 함수(예: $w = \exp(-d/\sigma)$, 여기서 $d$는 거리, $\sigma$는 스케일 파라미터)를 통해 계산되며, 가중치가 높을수록 두 노드 간 유사도가 높음을 의미한다. 이를 통해 단순히 연결 여부뿐만 아니라 연결의 강도까지 그래프 구조에 반영할 수 있다.

## 7. 노출 위험 척도 제안

노출위험은 크게 **식별자 노출위험**과 **속성 노출위험**의 두 가지 차원에서 평가한다.

### 식별자 노출위험

식별자 노출위험은 특정 노드가 전체 네트워크 내에서 구조적 혹은 통계적으로 고립된 형태를 보일 때 발생할 것으로 예상한다. 이는 weighted degree centrality의 역수로 표현할 수 있다. 노드 $i$에 연결된 모든 엣지의 가중치 합을 $S_i$라고 할 때, 다음과 같이 수식화할 수 있다.

$$
IDR_i = \frac{1}{1 + S_i}
$$

$S_i$가 낮다는 것은 이웃들이 $k$개 있더라도 노드 간 거리가 멀다는 것을 의미하므로 고립되었음을 뜻한다. 따라서 $S_i$가 낮을수록 식별자 노출 위험이 높아야 하므로 역수를 취하여 사용하고, 분모에 1을 더해 0으로 나누는 것을 방지한다.

### 속성 노출위험

반면, 속성 노출위험은 개별 식별자는 다르더라도, 다수의 노드가 매우 높은 속성 유사성을 공유하여 특정 속성 조합이 노출될 경우 나머지 속성까지 추론 가능성이 높아질 때 증가할 것으로 예상한다. 이는 weighted clustering coefficient를 활용하여 다음과 같이 표현한다.

$$
ADR_i = \frac{1}{S_i(k_i-1)} \sum_{j \neq i} \sum_{k \neq i,j} \frac{w_{ij} + w_{ik}}{2} a_{jk} w_{jk}
$$

여기서 $k_i$는 노드 $i$의 이웃 수, $S_i$는 노드 $i$에 연결된 모든 엣지 강도의 합, $a_{jk}$는 노드 $j$와 $k$가 연결되어 있으면 1, 아니면 0을 가지는 인접 행렬의 원소다. 즉, 분석의 대상이 되는 노드와 삼각관계를 이루고 있는 노드들 간의 연결된 정도를 모두 합산하고 정규화 함으로써 해당 노드 주변이 얼마나 밀집되어 있는가를 평가할 수 있다.

### 최종 노출 위험 척도

마지막으로, 두 위험 차원은 서로 상반된 방향성을 지니므로, 개별 관측치의 최종 노출위험 척도는 다음과 같이 두 위험 중 더 높은 값을 취하는 방식으로 정의한다. 노드 $i$에 대한 최대 노출 위험을 수식으로 표현하면 다음과 같이 적을 수 있다.

$$
MDR_i = \max(\alpha IDR_i, \beta ADR_i)
$$

이를 통해 관측치 단위에서의 가장 취약한 방향의 위험을 대표값으로 제시할 수 있다. $\alpha$와 $\beta$는 각각 사용자가 설정하는 하이퍼파라미터로 설정한다. 데이터셋 단위 노출 위험은 개별 관측치 단위 노출 위험도의 상위 $n\%$의 평균값으로 측정한다.

## 8. 프로젝트 예상 결과물

본 프로젝트의 수행을 통해 기대할 수 있는 주요 성과는 다음 두 가지로 요약된다.

**첫째**, 제안된 방법론은 도메인 사전지식이나 복잡한 피처 엔지니어링에 대한 의존도를 최소화한다. 데이터의 속성이 수치형 또는 범주형인지 여부만 식별되면, 이에 맞는 자동화된 전처리 파이프라인을 통해 그래프 기반 노출 위험 측정이 가능하다. 또한, 분석 목적에 따라 특정 속성을 선택적으로 제외하거나 부분 데이터만을 활용해 그래프를 재구성할 수 있어, 유연한 위험도 분석 환경을 제공한다.

**둘째**, 본 연구의 그래프 기반 접근법은 전통적인 빈도 기반 노출 위험 측정 기법(k-anonymity, l-diversity 등)의 한계를 보완한다. 기존 기법들이 관측치 간의 미세한 차이에도 민감하게 반응하는 반면, 거리 기반 가중치를 반영한 그래프 네트워크는 유사한 노드 간의 연관성까지 포착하여 보다 연속적이고 현실적인 위험 평가를 가능하게 한다. 이를 통해 데이터의 구조적 유사성을 보존하면서도, 노출 위험을 정량적으로 평가할 수 있는 편리한 분석 틀을 제시할 것으로 기대된다.
